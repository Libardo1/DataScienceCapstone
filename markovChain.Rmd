---
title: "MarkovChain"
output: html_document
---

```{r setupEnvironment}
library(ggplot2)
library(Gmisc)
library(rJava)
library(RWeka)
library(R.utils)
library(stringi)
library(stringr)
library(textcat)
library(tm)
library(xtable)
library(markovchain)

source("./determineTextFileSize.R")
source("./determineWordCount.R")
source("./formLineCorpus.R")
source("./sampleTextFile.R")
```

```{r updateLineCorpus}
updateLineCorpus <- FALSE
if (updateLineCorpus)
    blackList <- read.csv("./Data/Terms-to-Block.csv",header=FALSE,skip=4)
    blackList <- blackList[,2]
    blackList <- gsub(",","",blackList)
    blackList <- gsub(" ","",blackList)
    blackList <- gsub("[0-9]+","",blackList)
    blackList <- gsub("[\\.-]","",blackList)
    blackList <- blackList[!grepl("^a$",blackList)]
    blackList <- unique(blackList[blackList != ""])

    outputTextFileDirectory <- "./OutputData//en_US/"
    percentageToSample <- 1

    outputFilePath <- 
        determineSampledTextFileSize(outputTextFileDirectory,
                                     percentageToSample)
    load(outputFilePath)

    languageId <- basename(outputTextFileDirectory)
    
    samplingStr <- initializeSamplingString(percentageToSample)
    
    sampledTextFileRegex <- 
        initializeSampledTextFileRegex(percentageToSample)

    lineCorpusFile <- file.path(outputTextFileDirectory,
                                pattern=paste0(languageId,
                                               samplingStr,
                                               "LineCorpus.RData"))

    unlink(lineCorpusFile)
    lineCorpus <- list()  
    for (curTextFile in dir(outputTextFileDirectory,
                            pattern=sampledTextFileRegex)) {
        lineCorpus[[curTextFile]] <- 
            formLineCorpus(outputTextFileDirectory,
                           curTextFile,
                           "english",
                           sampledDocNumLines,
                           blackList,
                           TRUE)
    }
    save(file=lineCorpusFile, lineCorpus)    
}
load(lineCorpusFile)
```

```{r prototypeMarkovChain, echo=FALSE}
stateNames <- c("a","b","c")
markovB <- new("markovchain",
               transitionMatrix = matrix(c(0.2,0.5,0.3,
                                           0,1,0,
                                           0.1,0.8,0.1),
                                         byrow=TRUE,
                                         nrow=3,
                                        dimnames=list(stateNames,stateNames)))
```

```{r loadData}
outputTextFileDirectory <- "./OutputData//en_US/"

percentageToSample <- 1
samplingStr <- initializeSamplingString(percentageToSample)

languageId <- basename(outputTextFileDirectory)

lineCorpusFile <- file.path(outputTextFileDirectory,
                            pattern=paste0(languageId,
                                           samplingStr,
                                           "LineCorpus.RData"))

load(lineCorpusFile)

sampledTextFiles <- names(lineCorpus)
for (n in seq_len(length(sampledTextFiles))) {
    if (n == 1){
        combinedCorpus <- lineCorpus[[sampledTextFiles[n]]]
    } else {
        combinedCorpus <- c(combinedCorpus,
                            lineCorpus[[sampledTextFiles[n]]])
    }
}
rm(lineCorpus)

tdm <- as.matrix(TermDocumentMatrix(combinedCorpus))
termFreqs <- sort(rowSums(tdm), decreasing=TRUE)
termPDF <- termFreqs / sum(termFreqs)
termCDF <- cumsum(termPDF)
```

```{r tokenizeTrigrams}
TrigramTokenizer <- function(x) {
    RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 3, max = 3))
}

for (n in seq(1,length(combinedCorpus))) {
    if (n %% 10 == 0) {
        print(sprintf("line #%d", n))    
    }
    
    lineCorpus <- Corpus(VectorSource(as.character(combinedCorpus[[n]])))

    curTdm <- TermDocumentMatrix(lineCorpus,
                                 control = list(tokenize = TrigramTokenizer))
    
    if (n == 1) {
        triTdm <- curTdm
    } else {
        triTdm <- c(triTdm,curTdm)
    }
}
triTdm <- sort(rowSums(as.matrix(triTdm)), decreasing=TRUE)
save(file="./triTdm",triTdm,termPDF,termCDF)

trigrams <- names(triTdm)
commonIdx <- numeric()

sixtyFivePercentIdx <- which(termCDF >= 0.65)[1]

vocabularyCorpus <- 
    Corpus(VectorSource(names(termCDF[1:sixtyFivePercentIdx])))

vocabularyCorpus <- tm_map(vocabularyCorpus, removeWords, blackList)

for (n in seq_len(length(trigrams))) {
    if (n %% 100 == 0) {
        print(sprintf("Trigram #%d (Out of %d)", n, length(trigrams)))    
    }
    
    curWords <- unlist(str_split(trigrams[n]," "))
    
    if (sum(curWords %in% vocabulary) >= 2) {
        commonIdx <- append(commonIdx,n)
        vocabulary <- append(vocabulary,curWords[!curWords %in% vocabulary])        
    }
}
vocabulary <- sort(vocabulary[grep("^[^0-9]+$",vocabulary)])
save(file="./prediction.RData",list=ls())
```

```{r predictor0}
load("./prediction.RData")
triTdm0 <- head(triTdm,n=50)

predictorVocabulary <- sort(unique(unlist(str_split(paste(names(triTdm0),
                                                          collapse=" "),
                                                    " "))))

predictorVocabularySize <- length(predictorVocabulary)

transitionMatrix = matrix(numeric(predictorVocabularySize^2),
                                  byrow=TRUE,
                                  nrow=predictorVocabularySize,
                                  dimnames=list(predictorVocabulary,
                                                predictorVocabulary))

for (m in seq_len(length(triTdm0))) {
    curWords <- unlist(str_split(names(triTdm0[m])," "))
    
    for (n in seq(2,3)) {
        rowIdx <- which(grepl(paste0("^",curWords[n-1],"$"),
                              predictorVocabulary))
        colIdx <- which(grepl(paste0("^",curWords[n],"$"),
                                     predictorVocabulary))
        transitionMatrix[rowIdx,colIdx] <- triTdm0[m]
    }
}

for (m in seq_len(nrow(transitionMatrix))) {
    curRowSum <- sum(transitionMatrix[m,])
    
    if (curRowSum > 0) {
        transitionMatrix[m,] = transitionMatrix[m,] / curRowSum
    } else {
        transitionMatrix[m,m] = 1
    }
}

textPredictor <- new("markovchain",
                     transitionMatrix=transitionMatrix)

for (m in seq_len(length(triTdm0))) {
    print("-------------------------------------------")
    print(triTdm0[m])
    
    curState <- unlist(str_split(names(triTdm0[m])," "))[1]
    for (n in seq(1,2)) {
        curCondProb <- conditionalDistribution(textPredictor,
                                               curState)
        maxIdx <- which.max(curCondProb)
        nextState <- names(curCondProb[maxIdx])
        print(sprintf("%s -> %s (P: %g)",curState,
                                         nextState,
                                         curCondProb[maxIdx]))
        curState <- nextState
    }    
}
```

```{r predictor}
load("./prediction.RData")

vocabularySize <- length(vocabulary)

transitionMatrix = matrix(numeric(vocabularySize^2),
                                  byrow=TRUE,
                                  nrow=vocabularySize,
                                  dimnames=list(vocabulary,
                                                vocabulary))

for (m in seq_len(length(triTdm0))) {
    curWords <- unlist(str_split(names(triTdm0[m])," "))
    
    for (n in seq(2,3)) {
        rowIdx <- which(grepl(paste0("^",curWords[n-1],"$"),
                              predictorVocabulary))
        colIdx <- which(grepl(paste0("^",curWords[n],"$"),
                                     predictorVocabulary))
        transitionMatrix[rowIdx,colIdx] <- triTdm0[m]
    }
}

for (m in seq_len(nrow(transitionMatrix))) {
    curRowSum <- sum(transitionMatrix[m,])
    
    if (curRowSum > 0) {
        transitionMatrix[m,] = transitionMatrix[m,] / curRowSum
    } else {
        transitionMatrix[m,m] = 1
    }
}

textPredictor <- new("markovchain",
                     transitionMatrix=transitionMatrix)

for (m in seq_len(length(triTdm0))) {
    print("-------------------------------------------")
    print(triTdm0[m])
    
    curState <- unlist(str_split(names(triTdm0[m])," "))[1]
    for (n in seq(1,2)) {
        curCondProb <- conditionalDistribution(textPredictor,
                                               curState)
        maxIdx <- which.max(curCondProb)
        nextState <- names(curCondProb[maxIdx])
        print(sprintf("%s -> %s (P: %g)",curState,
                                         nextState,
                                         curCondProb[maxIdx]))
        curState <- nextState
    }    
}
```