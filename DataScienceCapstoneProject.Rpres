JHU Data Science Coursera Specialization Capstone Project
========================================================
author: mspcvsp
date: December 14, 2014
transition: rotate
font-family: 'Helvetica'

Project Summary
========================================================
```{r setupEnvironment, echo=FALSE}
# http://stackoverflow.com/questions/13090838/r-markdown-avoiding-package-loading-messages
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_20')

library(rJava)
library(RWeka)
library(R.utils)
library(stringi)
library(stringr)
library(shiny)
library(textcat)
library(tm)
library(markovchain)
library(ggplot2)
library(RColorBrewer)

source("./sampleTextFile.R")
source("./formLineCorpus.R")
source("./determineTextFileSize.R")
source("./analyzeUnigramStatistics.R")
source("./evaluateTextPredictorPerformance.R")
source("./constructTransitionMatrix.R")
```

- Problem statement
    - Implement a Shiny application that predicts the next word based on a 
    phrase entered by a user
- Challenges
    - Frequency of word occurence in text follows a [power law](http://nlp.stanford.edu/IR-book/html/htmledition/zipfs-law-modeling-the-distribution-of-terms-1.html) relationship
        - [~7K vocabulary](http://rpubs.com/mspcvsp/capstoneProjectEDA) is 
        required to model 90% of unique words contained in 1% of project text 
        data
    - [Limited memory](https://groups.google.com/forum/#!msg/shiny-discuss/IFpkIuPTVRU/P3D4AuNRkUAJ) available for a deployed Shiny application
- Solution
    - Implement [Markov chain](http://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html) text prediction algorithm based on a vocabulary that models 68% of unique
    words in a 60% training data set

Predictor User Interface
========================================================

![Shiny Application User Interface](./figures/userInterface.png)

- [Text Predictor](https://github.com/datasciencespm/DataScienceCapstone/tree/master/shinyApplication) User Interface:
    - Step #1: Launch application by navigating to the [Shiny application URL](http://datasciencespm.shinyapps.io/EnglishLanguageTextPredictor)  
    - Step #2: Enter a text phrase into the text input box
    - Step #3: Press the "Predict Word Button"


Predictor Training & Testing Approach
========================================================

- Predictor training & testing approach
    - Count number of trigrams that are contained in a vocabulary
    - Each trigram is composed of two Markov chain state transitions
    - Compute average number of state transitions across English language 
    training data 
    - Refine transition matrix based on 20% test data
    - Evaluate predictor performance using 20% validation data
    
- [Text model training R script](https://github.com/datasciencespm/DataScienceCapstone/blob/master/constructTextModel.Rmd)

Project Conclusion
========================================================

```{r echo=FALSE, fig.width=10, fig.height=3, fig.align='center'}
# https://support.rstudio.com/hc/communities/public/questions/
#   202702586-Figure-dimensions-in-Rpres-presentations
load(file="./OutputData//en_US/refinedVocabularyCounts.RData")

outputDataPath = "./OutputData//en_US"

trigramCount <- 0
commonTrigramCount <- 0
numCorrectPredictions <- 0
incorrectPredictions <- character()

for (curResultsFile in dir(outputDataPath,
                           pattern="*ValidationDataEval.RData")) {
    load(file.path(outputDataPath,curResultsFile))
    
    trigramCount <- trigramCount + textFileEval$trigramCount
    commonTrigramCount <- commonTrigramCount + textFileEval$commonTrigramCount
    
    numCorrectPredictions <-
        numCorrectPredictions + textFileEval$numCorrectPredictions
    
    incorrectPredictions <- append(incorrectPredictions,
                                   textFileEval$incorrectPredictions)
    
    rm(textFileEval)
}

percentTrigramsCovered <- round(100*(commonTrigramCount / trigramCount),1)

predictorPerformance <- 
    round(100*(numCorrectPredictions / commonTrigramCount),1)

vocabularyDistribution <- 
    initializeVocabularyDistribution(vocabularyCounts)

ggplot(vocabularyDistribution,aes(x=zerocounts,y=counts)) + stat_binhex() +
    facet_wrap(~type) + theme_gray(base_size=12) + 
    xlab("Zero Counts (Fraction of Vocabulary)") + 
    ylab("Counts (Fraction of Voabulary)")
```

- <small style="font-size:.7em">Validation data set analysis suggests `r percentTrigramsCovered` percent 
trigrams were covered by the training data set vocabulary</small>
    - <small style="font-size:.7em">`r predictorPerformance` % of validation data set triagram last words were 
    correctly predicted</small>
- <small style="font-size:.7em">Zero-Counts/Counts scatter plots suggest that there are a significant number of missing values in the transition matrix</small>
    - <small style="font-size:.7em">Consistent with low predictor performance</small>
- <small style="font-size:.7em">Proposed solution to improve predictor performance</small>
    - <small style="font-size:.7em">Evaluate training the Markov chain transition matrix using [Apache Hadoop](http://hadoop.apache.org/)</small>
        - <small style="font-size:.7em">[Real-Time Fraud Detection with Sequence Mining](https://pkghosh.wordpress.com/2013/10/21/real-time-fraud-detection-with-sequence-mining/)</small>
