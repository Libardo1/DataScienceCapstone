---
title: "Data Science Specialization Capstone Project Exploratory Data Analysis"
author: "mspcvsp"
date: "Monday, November 10, 2014"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
    css: styles.css
---  

```{r setupEnvironment, include=FALSE}
# http://stackoverflow.com/questions/13090838/r-markdown-avoiding-package-loading-messages
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_20')

library(Gmisc)
library(rJava)
library(RWeka)
library(R.utils)
library(tm)
library(stringr)
library(stringi)
library(textcat)
library(xtable)

if (!file.exists("./Data/final")) {
    unzip("./Data/Coursera-SwiftKey.zip", exdir="./Data")   
    
    # Profanity filter
    profanityBlackListURL <-
        paste0("http://www.frontgatemedia.com/new/wp-content/uploads/2014/03/",
               "Terms-to-Block.csv")
    
    download.file(url = profanityBlackListURL,
                  destfile="./Data/Terms-to-Block.csv")
}

blackList <- read.csv("./Data/Terms-to-Block.csv",header=FALSE,skip=4)
blackList <- blackList[,2]
blackList <- gsub(",","",blackList)

source("./determineTextFileSize.R")
source("./determineWordCount.R")
source("./formLineCorpus.R")
source("./sampleTextFile.R")
```

## Introduction

- The objective of the Data Science Capstone project is to develop an application that
predicts the next word a user will type into a mobile device
    - [Capstone Project Introduction](http://simplystatistics.org/2014/08/19/swiftkey-and-johns-hopkins-partner-for-data-science-specialization-capstone/)  
-  The purpose of this presentation is to discuss the following topics:
    - Summarize the statistics of the Capstone project text data sets
    - Describe unusual characteristics of this data  
- [An ISO 639-1 Language Code](http://www.w3schools.com/tags/ref_language_codes.asp)
    - Two-character string that refers to a language
    - Data Science Capstone project text data spans the following languages:  
        - English (EN)  
        - Finnish (FI)  
        - Germain (DE)  
        - Russian (RU)  
- The source code for this presentation has been uploaded to Github
    - [Data Science Capstone project Github repository](https://github.com/datasciencespm/DataScienceCapstone/tree/master)  

## Introduction
- This presentation will discuss the following summary statistics
    - Number of lines in each text file
    - Number of words in each text file
    - Word feature analysis

- There are three language models evaluated in this report
    - Unigram
        - Single word features
    - Bigram
        - Word pairs
    - Trigram
        - Three word segment
    - [Stanford Information Retrieval textbook language models summary](http://nlp.stanford.edu/IR-book/html/htmledition/types-of-language-models-1.html)

## Count the number of lines 
- Approach for counting the number of lines
    - Call R.utils [`countLines`](http://www.inside-r.org/packages/cran/R.utils/docs/countLines) function
    - Store number of text file lines in a list that is written to disk
    - [R script source code](https://github.com/datasciencespm/DataScienceCapstone/blob/master/determineTextFileSize.R)  
- Results presentation
    - [Format HTML table in R](http://stackoverflow.com/questions/20200082/formatting-html-table-in-r)
    - [Configure HTML table style using a Cascading Style Sheet (CSS)](http://stackoverflow.com/questions/21291762/css-how-to-define-a-class-for-table-to-control-the-style-of-table-rows)  
    - [HTML CSS Syntax](http://www.w3schools.com/css/css_table.asp)  
    - ["Stylish CSS Tables Tutorial"](http://cssmenumaker.com/blog/stylish-css-tables-tutorial)  

## Count the number of lines {.columns-2}
```{r, echo=FALSE, results='hide'}
#http://stackoverflow.com/questions/22871611/how-can-i-fix-column-breaks-in-an-rmarkdown-ioslides-presentation
baseTextFilePath <- "./Data/final"
baseOutputDataPath <- "./OutputData"

if (!file.exists(baseOutputDataPath)) {
    dir.create(baseOutputDataPath)
}

for (curLanguage in dir(baseTextFilePath)) {
    curOutputDataPath <- file.path(baseOutputDataPath, curLanguage)
    
    if (!file.exists(curOutputDataPath)) {
        dir.create(curOutputDataPath)
    }

    determineTextFileSize(file.path(baseTextFilePath, curLanguage),
                          curOutputDataPath)
    
    load(file.path(baseOutputDataPath,
                   curLanguage,
                   paste0(curLanguage,"NumLines.RData")))
        
    determineWordCount(file.path(baseTextFilePath, curLanguage),
                       curOutputDataPath,
                       num_lines)
}
```

- German text documents # of lines:
```{r loadDENumberOfLines, echo=FALSE, results='asis'}
#http://stackoverflow.com/questions/20200082/formatting-html-table-in-r
#http://stackoverflow.com/questions/21291762/css-how-to-define-a-class-for-table-to-control-the-style-of-table-rows
#http://www.w3schools.com/css/css_table.asp
#http://cssmenumaker.com/blog/stylish-css-tables-tutorial
load("./OutputData//de_DE/de_DENumLines.RData")
num_lines = t(as.data.frame(num_lines))
colnames(num_lines) <- c("# of lines")
print(xtable(t(num_lines)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_lines)
```
</br>
- English text documents # of lines:  
```{r loadENNumberOfLines, echo=FALSE, results='asis'}
load("./OutputData//en_US/en_USNumLines.RData")
num_lines = t(as.data.frame(num_lines))
colnames(num_lines) <- c("# of lines")
print(xtable(t(num_lines)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_lines)
```
</br>
- Finnish text documents # of lines:
```{r loadFINumberOfLines, echo=FALSE, results='asis'}
load("./OutputData//fi_FI/fi_FINumLines.RData")
num_lines = t(as.data.frame(num_lines))
colnames(num_lines) <- c("# of lines")
print(xtable(t(num_lines)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_lines)
```
</br>
- Russian text documents # of lines:
```{r loadRUNumberOfLines, echo=FALSE, results='asis'}
load("./OutputData//ru_RU/ru_RUNumLines.RData")
num_lines = t(as.data.frame(num_lines))
colnames(num_lines) <- c("# of lines")
print(xtable(t(num_lines)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_lines)
```

## Count the number of words
- Approach for counting the number of lines
    - [Read the text file into memory in chunks](http://stackoverflow.com/questions/15532810/reading-40-gb-csv-file-into-r-using-bigmemory?lq=1)  
    - [Remove non-ASCII character from text](http://stackoverflow.com/questions/9934856/removing-non-ascii-characters-from-data-files)
    - [Count the number of words using the stringi R package `stri_stats_latex` function](http://www.r-bloggers.com/counting-the-number-of-words-in-a-latex-file-with-stringi/)  
    - Store the text file word count in a list that is written to disk
    - Present results in the same format at the number of lines / text file
    - [R script source code](https://github.com/datasciencespm/DataScienceCapstone/blob/master/determineWordCount.R)

## Count the number of words {.columns-2}
```{r countNumberOfWords, echo=FALSE, results='hide'}
#http://stackoverflow.com/questions/22871611/how-can-i-fix-column-breaks-in-an-rmarkdown-ioslides-presentation
if (!file.exists(baseOutputDataPath)) {
    dir.create(baseOutputDataPath)
}

for (curLanguage in dir(baseTextFilePath)) {
    curOutputDataPath <- file.path(baseOutputDataPath, curLanguage)
    
    load(file.path(baseOutputDataPath,
                   curLanguage,
                   paste0(curLanguage,"NumLines.RData")))
        
    determineWordCount(file.path(baseTextFilePath, curLanguage),
                       curOutputDataPath,
                       num_lines)
}
```

- German text documents # of words [millions]:
```{r loadDENumberOfWords, echo=FALSE, results='asis'}
load("./OutputData//de_DE/de_DENumWords.RData")
num_words = t(as.data.frame(num_words)) / 1E6
colnames(num_words) <- "# of words [millions]"
print(xtable(t(num_words)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_words)
```
</br>
- English text documents # of words [millions]:  
```{r loadENNumberOfWords, echo=FALSE, results='asis'}
load("./OutputData//en_US/en_USNumWords.RData")
num_words = t(as.data.frame(num_words)) / 1E6
colnames(num_words) <- "# of words [millions]"
print(xtable(t(num_words)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_words)
```
</br>
- Finnish text documents # of words [millions]:
```{r loadFINumberOfWords, echo=FALSE, results='asis'}
load("./OutputData//fi_FI/fi_FINumWords.RData")
num_words = t(as.data.frame(num_words)) / 1E6
colnames(num_words) <- "# of words [millions]"
print(xtable(t(num_words)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_words)
```
</br>
- Russian text documents # of words:
```{r loadRUNumberOfWords, echo=FALSE, results='asis'}
load("./OutputData//ru_RU/ru_RUNumWords.RData")
num_words = t(as.data.frame(num_words)) / 1E6
colnames(num_words) <- "# of words [millions]"
print(xtable(t(num_words)),
      type="html",
      html.table.attributes="class='table-bordered'")
rm(num_words)
```

## Word Features   
```{r randomlySampleEnglishTextDocuments, echo=FALSE, results='hide'}
set.seed(1089165195)
outputTextFileDirectory <- "./OutputData//en_US/"
percentageToSample <- 1

samplingStr <- initializeSamplingString(percentageToSample)

sampledTextFileRegex <- initializeSampledTextFileRegex(percentageToSample)

if (length(dir(outputTextFileDirectory,
               pattern=sampledTextFileRegex)) == 0){
    applyRandomSamplerToTextFiles("./Data/final//en_US/",
                                  percentageToSample,
                                  outputTextFileDirectory,
                                  TRUE) 
}

languageId <- basename(outputTextFileDirectory)

lineCorpusFile <- file.path(outputTextFileDirectory,
                            pattern=paste0(languageId,
                                           samplingStr,
                                           "LineCorpus.RData"))

if (!file.exists(lineCorpusFile)) {
    sampledTextFileSizePath <- 
        determineSampledTextFileSize(outputTextFileDirectory,
                                     percentageToSample)
    load(outputFilePath)

    lineCorpus <- list()    
    for (curTextFile in dir(outputTextFileDirectory,
                            pattern=sampledTextFileRegex)) {
        lineCorpus[[curTextFile]] <- 
            formLineCorpus(outputTextFileDirectory,
                           curTextFile,
                           "english",
                           sampledDocNumLines,
                           blackList,
                           TRUE)
    }
    save(file=lineCorpusFile, lineCorpus)    
}
load(lineCorpusFile)
```
